{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DTCNN-ELM for LIDC-IDRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import datetime\n",
    "import time\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from utils import make_dir\n",
    "import hpelm\n",
    "from sklearn import svm\n",
    "from models import efficientnetb5_model\n",
    "from models import mobilenetv2_model\n",
    "from models import nasnetmobile_model\n",
    "from models import resnet50_model\n",
    "from models import xception_model\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "import keras\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# learning rate\n",
    "\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.01\n",
    "    drop = 0.5\n",
    "    epochs_drop = 4.0\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "# Config\n",
    "\n",
    "\n",
    "class DefaultConfigs(object):\n",
    "    # --------------------------------------- Parameters --------------------------------------\n",
    "    # String parameters\n",
    "    PROJECT = 'LIDC'\n",
    "    DTCNN_NAME = {0: 'ResNet50',\n",
    "                  1: 'Xception',\n",
    "                  2: 'EfficientNet-B5',\n",
    "                  3: 'NASNetMobile',\n",
    "                  4: 'MobileNetV2'}\n",
    "    CLASSES_NAME = {0: 'Benign', 1: 'Malignant'}\n",
    "    # Numeric parameters\n",
    "    SEED = 66  # seed\n",
    "    EP = 10  # epochs\n",
    "    BS = 64  # batch_size\n",
    "    NUM_CLASSES = 2\n",
    "    LR = 2e-5  # fixed learning rate (test)\n",
    "    DATE_STR = datetime.datetime.now().strftime('%Y%m%d')\n",
    "    # -----------------------------------------------------------------------------------------\n",
    "\n",
    "    # --------------------------------------- Directory ---------------------------------------\n",
    "    # Data directory\n",
    "    DATA_PATH = \"data/demo.npz\"\n",
    "    #DATA_PATH = \"data/LIDC-IDRI.npz\"\n",
    "    # Save directory\n",
    "    CHECKPOINTS_SAVE_DIR = \"./results/checkpoints/\"\n",
    "    BEST_MODEL_SAVE_DIRbest = CHECKPOINTS_SAVE_DIR + \"best_model/\"\n",
    "    RESUTLS_SAVE_DIR = \"./results/\"\n",
    "    LOGS_SAVE_DIR = RESUTLS_SAVE_DIR + \"logs/\"\n",
    "    # -----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "conf = DefaultConfigs()\n",
    "np.random.seed(conf.SEED)\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = np.load(conf.DATA_PATH)\n",
    "datas_raw = datasets[\"imgs\"]\n",
    "labels = datasets[\"labels\"]\n",
    "datas_reshape = datas_raw.reshape(datas_raw.shape[0],64,64)  \n",
    "datas = datas_reshape.astype('float32')\n",
    "datas /= 255.\n",
    "print(datas.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "\n",
    "# define 5-fold cross validation test harness\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=conf.SEED)\n",
    "Acc1 = []\n",
    "Sen1 = []\n",
    "Spc1 = []\n",
    "AUC1 = []\n",
    "Train_time1 = []\n",
    "Test_time1 = []\n",
    "\n",
    "Acc2 = []\n",
    "Sen2 = []\n",
    "Spc2 = []\n",
    "AUC2 = []\n",
    "Train_time2 = []\n",
    "Test_time2 = []\n",
    "\n",
    "Acc3 = []\n",
    "Sen3 = []\n",
    "Spc3 = []\n",
    "AUC3 = []\n",
    "Train_time3 = []\n",
    "Test_time3 = []\n",
    "\n",
    "iLayer = 1\n",
    "iFold = 1\n",
    "\n",
    "for train, test in kfold.split(datas, labels):\n",
    "    print('-----------Fold %s Begin-----------' % iFold)\n",
    "    train_data = datas[train]\n",
    "    train_label = to_categorical(labels[train], 2)\n",
    "    test_data = datas[test]\n",
    "    test_label = to_categorical(labels[test], 2)\n",
    "    \n",
    "    ##################\n",
    "    ## DTCNN Softmax\n",
    "    ##################\n",
    "    # Create the source DCNN model\n",
    "    model = xception_model((64,64),conf.NUM_CLASSES) \n",
    "    # Target DTCNN model with deep transfer learning\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    # Train target DTCNN with Softmax classifier\n",
    "    dtcnn_softmax_train_start = time.time()\n",
    "    \n",
    "    model_hst = model.fit(x=train_data, y=train_label,\n",
    "                          batch_size=conf.BS, epochs=conf.EP,\n",
    "                          callbacks=[lrate],\n",
    "                          verbose=0,\n",
    "                          )\n",
    "    \n",
    "    dtcnn_softmax_train_end = time.time()\n",
    "    \n",
    "    # Test Target DTCNN with Softmax classifier\n",
    "    dtcnn_softmax_test_sart = time.time()\n",
    "    \n",
    "    dtcnn_pre = model.predict(test_data)\n",
    "    \n",
    "    dtcnn_softmax_test_end = time.time()\n",
    "    \n",
    "    # Evaluation for DTCNN with softmax\n",
    "    dtcnn_class_results = np.array([np.argmax(r) for r in dtcnn_pre])\n",
    "    tn1, fp1, fn1, tp1 = confusion_matrix(labels[test], dtcnn_class_results).ravel()\n",
    "    accuracy1 = (tp1+tn1)/(tp1+tn1+fp1+fn1)\n",
    "    sensitivity1 = tp1/(tp1+fn1)\n",
    "    specificity1 = tn1/(tn1+fp1)\n",
    "    auc1 = roc_auc_score(labels[test], dtcnn_class_results)\n",
    "    dtcnn_softmax_train_time = dtcnn_softmax_train_end - dtcnn_softmax_train_start\n",
    "    dtcnn_softmax_test_time = dtcnn_softmax_test_end - dtcnn_softmax_test_sart\n",
    "    print('dtcnn_softmax_acc: %.4f' % accuracy1)\n",
    "    print('dtcnn_softmax_sen: %.4f' % sensitivity1)\n",
    "    print('dtcnn_softmax_spc: %.4f' % specificity1)\n",
    "    print('dtcnn_softmax_auc: %.4f' % auc1)\n",
    "    print('dtcnn_softmax_training_time: %.4f s' % dtcnn_softmax_train_time)\n",
    "    print('dtcnn_softmax_testing_time: %.4f s' % dtcnn_softmax_test_time)\n",
    "    Acc1.append(accuracy1 * 100)\n",
    "    Sen1.append(sensitivity1 * 100)\n",
    "    Spc1.append(specificity1 * 100)\n",
    "    AUC1.append(auc1 * 100)\n",
    "    Train_time1.append(dtcnn_softmax_train_time)\n",
    "    Test_time1.append(dtcnn_softmax_test_time)\n",
    "    \n",
    "    ##################\n",
    "    ## DTCNN ELM\n",
    "    ##################\n",
    "    layer_name = 'global_average_pooling2d_' + str(iLayer)\n",
    "    iLayer = iLayer + 1\n",
    "    dtcnn_model = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "    \n",
    "    # train DTCNN-ELM (two step)\n",
    "    dtcnn_elm_train_strat1 = time.time()\n",
    "    dtcnn_elm_train_feature = dtcnn_model.predict(train_data)\n",
    "    dtcnn_elm_train_end1 = time.time()\n",
    "    \n",
    "    elm_model = hpelm.hp_elm.HPELM(dtcnn_elm_train_feature.shape[1], 2)\n",
    "    elm_model.add_neurons(500, func='sigm')\n",
    "    \n",
    "    dtcnn_elm_train_strat2 = time.time()\n",
    "    elm_model.train(dtcnn_elm_train_feature, train_label, 'c')\n",
    "    dtcnn_elm_train_end2 = time.time()\n",
    "    \n",
    "    # test DTCNN-ELM \n",
    "    dtcnn_elm_test_strat = time.time()\n",
    "    dtcnn_elm_test_feature = dtcnn_model.predict(test_data)\n",
    "    dtcnn_elm_test = elm_model.predict(dtcnn_elm_test_feature)\n",
    "    dtcnn_elm_test_end = time.time()\n",
    "    \n",
    "    # Evaluation for DTCNN-ELM\n",
    "    dtcnn_elm_class_results = np.array([np.argmax(r) for r in dtcnn_elm_test])\n",
    "    tn2, fp2, fn2, tp2 = confusion_matrix(labels[test], dtcnn_elm_class_results).ravel()\n",
    "    accuracy2 = (tp2+tn2)/(tp2+tn2+fp2+fn2)\n",
    "    sensitivity2 = tp2/(tp2+fn2)\n",
    "    specificity2 = tn2/(tn2+fp2)\n",
    "    auc2 = roc_auc_score(labels[test], dtcnn_elm_class_results)\n",
    "    dtcnn_elm_train_time = dtcnn_elm_train_end1-dtcnn_elm_train_strat1+dtcnn_elm_train_end2-dtcnn_elm_train_strat2\n",
    "    dtcnn_elm_test_time = dtcnn_elm_test_end - dtcnn_elm_test_strat\n",
    "    print('dtcnn_elm_acc: %.4f' % accuracy2)\n",
    "    print('dtcnn_elm_sen: %.4f' % sensitivity2)\n",
    "    print('dtcnn_elm_spc: %.4f' % specificity2)\n",
    "    print('dtcnn_elm_auc: %.4f' % auc2)\n",
    "    print('dtcnn_elm_training_time: %.4f s' % dtcnn_elm_train_time)\n",
    "    print('dtcnn_elm_testing_time: %.4f s' % dtcnn_elm_test_time)\n",
    "\n",
    "    Acc2.append(accuracy2 * 100)\n",
    "    Sen2.append(sensitivity2 * 100)\n",
    "    Spc2.append(specificity2 * 100)\n",
    "    AUC2.append(auc2 * 100)\n",
    "    Train_time2.append(dtcnn_elm_train_time)\n",
    "    Test_time2.append(dtcnn_elm_test_time)\n",
    "    \n",
    "    ##################\n",
    "    ## DTCNN SVM\n",
    "    ##################\n",
    "    svm_model = svm.SVC(C=0.5)\n",
    "    #c_range = np.array([0.0005, 0.005, 0.05, 0.5, 5])\n",
    "    #param_grid = [{'kernel': ['rbf'], 'C': c_range}]\n",
    "    #grid = GridSearchCV(svm_model, param_grid, n_jobs=-1, cv=kfold)\n",
    "    \n",
    "    # train DTCNN-SVM\n",
    "    dtcnn_svm_train_strat = time.time()\n",
    "    dtcnn_svm_train_feature = dtcnn_model.predict(train_data)\n",
    "    #dtcnn_svm_train_feature_std = scaler.fit_transform(dtcnn_svm_train_feature)\n",
    "    svm_model.fit(dtcnn_svm_train_feature, labels[train])\n",
    "    #svm_grid = grid.fit(dtcnn_svm_train_feature_std, labels[train])\n",
    "    #print(\"Best: %f using %s\" % (svm_grid.best_score_,grid.best_params_))\n",
    "    dtcnn_svm_train_end = time.time()\n",
    "    \n",
    "    # test DTCNN-SVM\n",
    "    dtcnn_svm_test_strat = time.time()\n",
    "    dtcnn_svm_test_feature = dtcnn_model.predict(test_data)\n",
    "    #dtcnn_svm_test_feature_std = scaler.fit_transform(dtcnn_svm_test_feature)\n",
    "    dtcnn_svm_result = svm_model.predict(dtcnn_svm_test_feature)\n",
    "    dtcnn_svm_test_end = time.time()\n",
    "    \n",
    "    # Evaluation for DTCNN-SVM\n",
    "    tn3, fp3, fn3, tp3 = confusion_matrix(labels[test], dtcnn_svm_result).ravel()\n",
    "    accuracy3 = (tp3+tn3)/(tp3+tn3+fp3+fn3)\n",
    "    sensitivity3 = tp3/(tp3+fn3)\n",
    "    specificity3 = tn3/(tn3+fp3)\n",
    "    auc3 = roc_auc_score(labels[test], dtcnn_svm_result)\n",
    "    dtcnn_svm_train_time = dtcnn_svm_train_end - dtcnn_svm_train_strat\n",
    "    dtcnn_svm_test_time = dtcnn_svm_test_end - dtcnn_svm_test_strat\n",
    "    print('dtcnn_svm_acc: %.4f' % accuracy3)\n",
    "    print('dtcnn_svm_sen: %.4f' % sensitivity3)\n",
    "    print('dtcnn_svm_spc: %.4f' % specificity3)\n",
    "    print('dtcnn_svm_auc: %.4f' % auc3)\n",
    "    print('dtcnn_svm_training_time: %.4f s' % dtcnn_svm_train_time)\n",
    "    print('dtcnn_svm_testing_time: %.4f s' % dtcnn_svm_test_time)\n",
    "\n",
    "    Acc3.append(accuracy3 * 100)\n",
    "    Sen3.append(sensitivity3 * 100)\n",
    "    Spc3.append(specificity3 * 100)\n",
    "    AUC3.append(auc3 * 100)\n",
    "    Train_time3.append(dtcnn_svm_train_time)\n",
    "    Test_time3.append(dtcnn_svm_test_time)\n",
    "    \n",
    "    print('-----------Fold %s End-----------' % iFold)\n",
    "    iFold = iFold + 1\n",
    "    \n",
    "# Mean results\n",
    "print(\"-----------DTCNN_Softmax-----------\")\n",
    "print(\"Acc: %.2f%% (+/- %.2f%%)\" % (np.mean(Acc1), np.std(Acc1)))\n",
    "print(\"Sen: %.2f%% (+/- %.2f%%)\" % (np.mean(Sen1), np.std(Sen1)))\n",
    "print(\"Spc: %.2f%% (+/- %.2f%%)\" % (np.mean(Spc1), np.std(Spc1)))\n",
    "print(\"AUC: %.2f%% (+/- %.2f%%)\" % (np.mean(AUC1), np.std(AUC1)))\n",
    "print(\"Training Time: %.4f s\" % (np.mean(Train_time1)))\n",
    "print(\"Testing Time: %.4f s\" % (np.mean(Test_time1)))\n",
    "print(\"-----------DTCNN_Softmax-----------\")\n",
    "print(\"-----------------------------------\")\n",
    "print(\"-------------DTCNN_ELM-------------\")\n",
    "print(\"Acc: %.2f%% (+/- %.2f%%)\" % (np.mean(Acc2), np.std(Acc2)))\n",
    "print(\"Sen: %.2f%% (+/- %.2f%%)\" % (np.mean(Sen2), np.std(Sen2)))\n",
    "print(\"Spc: %.2f%% (+/- %.2f%%)\" % (np.mean(Spc2), np.std(Spc2)))\n",
    "print(\"AUC: %.2f%% (+/- %.2f%%)\" % (np.mean(AUC2), np.std(AUC2)))\n",
    "print(\"Training Time: %.4f s\" % (np.mean(Train_time2)))\n",
    "print(\"Testing Time: %.4f s\" % (np.mean(Test_time2)))\n",
    "print(\"-------------DTCNN_ELM-------------\")\n",
    "print(\"-----------------------------------\")\n",
    "print(\"-------------DTCNN_SVM-------------\")\n",
    "print(\"Acc: %.2f%% (+/- %.2f%%)\" % (np.mean(Acc3), np.std(Acc3)))\n",
    "print(\"Sen: %.2f%% (+/- %.2f%%)\" % (np.mean(Sen3), np.std(Sen3)))\n",
    "print(\"Spc: %.2f%% (+/- %.2f%%)\" % (np.mean(Spc3), np.std(Spc3)))\n",
    "print(\"AUC: %.2f%% (+/- %.2f%%)\" % (np.mean(AUC3), np.std(AUC3)))\n",
    "print(\"Training Time: %.4f s\" % (np.mean(Train_time3)))\n",
    "print(\"Testing Time: %.4f s\" % (np.mean(Test_time3)))\n",
    "print(\"-------------DTCNN_SVM-------------\")\n",
    "print(\"-----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
